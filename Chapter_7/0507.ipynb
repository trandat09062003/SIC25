{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7b41ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb7b5cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/thuong/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/thuong/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dc7bd1",
   "metadata": {},
   "source": [
    "1. More about the NLTK library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebc21dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  From the US president B. Obama's Nov-4th-2008 speech. \n",
    "#\n",
    "\n",
    "paragraph = \"\"\"If there is anyone out there who still doubts that America is a place where all things are possible; who still wonders if the dream of our founders is alive in our time; who still questions the power of our democracy: Tonight is your answer.\n",
    "It's the answer told by lines that stretched around schools and churches in numbers this nation has never seen; by people who waited three hours and four hours, many for the very first time in their lives, because they believed that this time must be different; that their voices could be that difference. \n",
    "It's the answer spoken by young and old, rich and poor, Democrat and Republican, black, white, Hispanic, Asian, Native American, gay, straight, disabled and not disabled -- Americans who sent a message to the world that we have never been just a collection of individuals or a collection of Red States and Blue States: we are, and always will be, the United States of America!\n",
    "It's the answer that -- that led those who have been told for so long by so many to be cynical, and fearful, and doubtful about what we can achieve to put their hands on the arc of history and bend it once more toward the hope of a better day.\n",
    "It's been a long time coming, but tonight, because of what we did on this day, in this election, at this defining moment, change has come to America.\n",
    "A little bit earlier this evening, I received an extraordinarily gracious call from Senator McCain. Senator McCain fought long and hard in this campaign, and he's fought even longer and harder for the country that he loves. He has endured sacrifices for America that most of us cannot begin to imagine. We are better off for the service rendered by this brave and selfless leader. I congratulate him; I congratulate Governor Palin for all that they've achieved, and I look forward to working with them to renew this nation's promise in the months ahead.\n",
    "I want to thank my partner in this journey, a man who campaigned from his heart and spoke for the men and women he grew up with on the streets of Scranton and rode with on the train home to Delaware, the Vice President-elect of the United States, Joe Biden. \"\"\"                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b46147",
   "metadata": {},
   "source": [
    "1.1. Tokenization and pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff7ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize into sentences.\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = sentences[i].lower()\n",
    "    sentences[i] = re.sub(r'\\W',' ',sentences[i])            # Substitute the non-alphanumeric characters with space. \n",
    "    sentences[i] = re.sub(r'\\s+',' ',sentences[i])           # Remove the excess of white spaces.\n",
    "    sentences[i] = re.sub(r'\\s$','',sentences[i])            # Remove the space at the end of a sentence.\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a508816",
   "metadata": {},
   "source": [
    "1.2. Removal of the stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e579a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35374cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])                                   # Tokenize into words.\n",
    "    words = [x for x in words if x not in stopwords.words('english')]         # Remove the stop words.\n",
    "    sentences[i] = ' '.join(words)                                             # Rejoin as a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bd7e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5eecc5",
   "metadata": {},
   "source": [
    "1.3. POS tagging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696fcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sentence.\n",
    "my_sentence = \"The Colosseum was built by the emperor Vespassian\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdc710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple pre-processing.\n",
    "my_words = nltk.word_tokenize(my_sentence)\n",
    "for i in range(len(my_words)):\n",
    "    my_words[i] = my_words[i].lower()\n",
    "my_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c3f731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagging.\n",
    "# OUTPUT: A list of tuples.\n",
    "my_words_tagged = nltk.pos_tag(my_words)\n",
    "my_words_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dd1c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the words + POS as a sentence.\n",
    "my_words_tagged2 = []\n",
    "for tw in my_words_tagged:\n",
    "    my_words_tagged2.append(tw[0] + '(' + tw[1] + ')')\n",
    "my_sentence_tagged = ' '.join(my_words_tagged2)\n",
    "my_sentence_tagged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
